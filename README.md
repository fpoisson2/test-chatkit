# ChatKit Sample

This repository mirrors the walkthrough in `chatkit.md`, providing both the legacy FastAPI endpoint that issues ChatKit client secrets and a lightweight ChatKit server (`/api/chatkit`) driven by the Python SDK. La base de code est scind√©e entre `backend/` et `frontend/` et inclut d√©sormais une authentification basique (connexion + r√¥les) ainsi qu'un panneau d'administration pour g√©rer les utilisateurs.

## Authentification et administration

- La connexion se fait depuis `/login` et repose sur un token JWT sign√© c√¥t√© backend.
- L'accueil (`/`) est prot√©g√© : sans authentification valide, l'utilisateur est redirig√© vers la page de connexion avant d'acc√©der au widget ChatKit.
- Un compte administrateur (cr√©√© via variables d'environnement) peut g√©rer les utilisateurs depuis `/admin`¬†: cr√©ation, promotion/d√©classement, r√©initialisation de mot de passe et suppression.
- L'onglet `/admin/vector-stores` r√©capitule les magasins JSON (`pgvector`) disponibles, permet d'en cr√©er de nouveaux, d'uploader un fichier JSON pour l'ing√©rer, de d√©clencher l'indexation et de tester les requ√™tes hybrides (`/search_json`) avec un aper√ßu du document source (`/documents/{doc_id}`).
- L'onglet `/admin/widgets` offre une interface compl√®te pour constituer la biblioth√®que de widgets ChatKit¬†: cr√©ation, validation/pr√©visualisation, √©dition et suppression des d√©finitions JSON avant leur utilisation dans le workflow builder.
- Les requ√™tes vers `/api/chatkit/session` utilisent automatiquement l'identit√© de l'utilisateur connect√© si un token est pr√©sent dans les en-t√™tes.
- Une impl√©mentation ChatKit auto‚Äëh√©berg√©e est disponible sur `/api/chatkit`. Elle orchestre l'Agents SDK en local pour r√©pondre via le widget sans passer par un workflow h√©berg√©.
- Les endpoints `/api/chatkit/session`, `/api/chatkit` et `/api/chatkit/proxy/*` exigent d√©sormais un JWT valide¬†: toute tentative non authentifi√©e renvoie `401` avant m√™me de contacter l'API ChatKit.

## Commandes depuis la racine

- `npm run backend:sync` ‚Äî installe les d√©pendances Python (utilise `uv` si pr√©sent, sinon bascule sur `python3 -m pip install -r backend/requirements.txt`)
- `npm run backend:dev` ‚Äî lance le serveur FastAPI (`uv run ‚Ä¶` si disponible, sinon `python3 -m uvicorn server:app --reload --app-dir backend`)
- `npm run frontend:install` ‚Äî installe les d√©pendances npm de `frontend/`
- `npm run frontend:dev` ‚Äî lance le serveur Vite
- `npm run frontend:build` ‚Äî construit le bundle de production
- `npm run frontend:preview` ‚Äî aper√ßu local du bundle

Le backend r√©f√©rence d√©sormais la copie locale du package `openai-chatkit` situ√©e dans `chatkit-python/`, ce qui garantit que `npm run backend:sync` synchronise la version embarqu√©e avec le reste du d√©p√¥t.

Les scripts utilisent `uv` et `npm` en ciblant les sous-dossiers, √©vitant ainsi les `cd`. Si `uv` n'est pas install√©, les commandes tombent automatiquement sur l'√©quivalent `python3 -m pip` / `python3 -m uvicorn`.

### Activer le mode voix

Le parcours vocal exploite WebRTC : pr√©voyez un navigateur r√©cent capable d'acc√©der au microphone via `navigator.mediaDevices.getUserMedia` et autorisez la permission audio lors du premier d√©marrage.„ÄêF:frontend/src/voice/VoiceChat.tsx‚Ä†L31-L63„Äë Un micro fonctionnel est indispensable pour initier la session.

Toutes les commandes ci-dessous se lancent **depuis la racine du d√©p√¥t**¬†:

```bash
# depuis la racine du d√©p√¥t
npm run backend:dev   # expose POST /api/chatkit/voice/session pour g√©n√©rer les secrets √©ph√©m√®res
npm run frontend:dev  # d√©marre le client Vite et la page /voice
```

L'appel `POST /api/chatkit/voice/session` retourne un `client_secret` temporaire, la configuration (mod√®le, voix, instructions) ainsi que l'horodatage d'expiration. Le backend s'appuie par d√©faut sur les variables `CHATKIT_REALTIME_MODEL`, `CHATKIT_REALTIME_INSTRUCTIONS` et `CHATKIT_REALTIME_VOICE`, mais vous pouvez les surcharger depuis l'interface admin (¬´¬†Param√®tres du mode voix¬†¬ª).„ÄêF:backend/app/routes/chatkit.py‚Ä†L154-L204„Äë„ÄêF:.env.example‚Ä†L12-L16„Äë

C√¥t√© navigateur, configurez la section ¬´¬†Param√©trage du mode voix¬†¬ª de votre `.env` Vite pour pointer vers le backend et d√©finir les valeurs par d√©faut utilis√©es avant la premi√®re personnalisation¬†:

```env
VITE_VOICE_SESSION_URL="/api/chatkit/voice/session"
VITE_VOICE_DEFAULT_MODEL="gpt-4o-realtime-preview-2024-12-17"
VITE_VOICE_DEFAULT_INSTRUCTIONS="Sois chaleureux et garde des r√©ponses courtes"
VITE_VOICE_DEFAULT_VOICE="verse"
```

Ces variables servent de repli lorsque la base de donn√©es ne contient pas encore de pr√©f√©rences vocales et permettent de diriger le frontend vers un backend distant si `VITE_BACKEND_URL` est renseign√©.„ÄêF:.env.example‚Ä†L44-L53„Äë„ÄêF:frontend/src/voice/useVoiceSession.ts‚Ä†L17-L48„Äë„ÄêF:frontend/src/voice/useVoiceSession.ts‚Ä†L324-L371„Äë Le secret renvoy√© par OpenAI expira rapidement¬†: le frontend anticipe un rafra√Æchissement environ une minute avant la date `expires_at`. Pr√©voyez de relancer la capture microphone si vous suspendez la session trop longtemps.„ÄêF:frontend/src/voice/useVoiceSession.ts‚Ä†L54-L68„Äë„ÄêF:frontend/src/voice/useVoiceSession.ts‚Ä†L406-L462„Äë

### Initialiser un vector store via l'interface admin

Toutes les commandes ci-dessous se lancent **depuis la racine du d√©p√¥t**¬†:

```bash
# depuis la racine du d√©p√¥t
npm run backend:sync   # installe les d√©pendances Python (pgvector, sentence-transformers‚Ä¶)
npm run backend:dev    # d√©marre FastAPI et initialise les tables json_vector_stores
npm run frontend:dev   # lance Vite pour acc√©der au panneau d'administration
```

Une fois les deux serveurs d√©marr√©s, ouvrez `http://localhost:5173/admin/vector-stores`¬†:

1. Cr√©ez un magasin (slug + m√©tadonn√©es) via **Nouveau vector store**.
2. D√©posez un fichier JSON et validez l'ingestion pour g√©n√©rer les embeddings.
3. Testez une requ√™te de recherche hybride et inspectez le document complet retourn√© par l'API.

> ‚ÑπÔ∏è **Versions toujours √† jour** ‚Äî les manifestes (`backend/requirements.txt`, `backend/pyproject.toml`, `frontend/package.json`) ne fixent plus de contrainte de version. Chaque ex√©cution de `npm run backend:sync` ou `npm run frontend:install` installe donc les derni√®res publications disponibles. Pensez √† r√©g√©n√©rer vos environnements locaux apr√®s un `git pull` pour r√©cup√©rer les √©volutions amont.

### G√©rer la biblioth√®que de widgets via l'interface admin

Toujours **depuis la racine du d√©p√¥t**¬†:

```bash
# depuis la racine du d√©p√¥t
npm run backend:dev   # expose les routes /api/widgets prot√©g√©es par authentification
npm run frontend:dev  # lance Vite et l'interface d'administration
```

Ouvrez ensuite `http://localhost:5173/admin/widgets`¬†:

1. Cliquez sur **Nouveau widget** pour saisir un slug, un titre et coller la d√©finition JSON (ex. un `Card` avec des `Text`).
2. Utilisez le bouton **Pr√©visualiser** pour valider la d√©finition c√¥t√© backend (`chatkit.widgets.WidgetRoot`) et visualiser le JSON normalis√©.
3. Enregistrez le widget pour le retrouver dans la table, pr√™t √† √™tre r√©f√©renc√© depuis vos modules d'agent (slug).
4. Ouvrez un widget existant pour le mettre √† jour ou supprimez-le lorsqu'il n'est plus utilis√©.

La pr√©visualisation en direct √©vite de propager des d√©finitions invalides dans vos workflows et fournit un exemple de JSON pr√™t √† copier/coller dans le workflow builder.

## Backend (`backend/`)

- Install dependencies via [uv](https://github.com/astral-sh/uv): `uv sync` (ou `npm run backend:sync` √† la racine)
- Cr√©ez un fichier `.env` dans `backend/` avec au minimum¬†:
  - `OPENAI_API_KEY` ‚Äì cl√© API autoris√©e sur la b√™ta ChatKit
  - `DATABASE_URL` ‚Äì URL SQLAlchemy vers PostgreSQL (ex. `postgresql+psycopg://chatkit:chatkit@localhost:5432/chatkit`). En
    environnement Docker¬†Compose, utilisez le hostname du service PostgreSQL (`db`) plut√¥t que `localhost`, par exemple
    `postgresql+psycopg://chatkit:chatkit@db:5432/chatkit`.
  - `AUTH_SECRET_KEY` ‚Äì cl√© secr√®te utilis√©e pour signer les tokens JWT
  - Optionnel¬†: `CHATKIT_WORKFLOW_ID` si vous souhaitez toujours pouvoir √©mettre un `client_secret` via l'API h√©berg√©e.
  - Optionnel¬†: `CHATKIT_AGENT_MODEL` / `CHATKIT_AGENT_INSTRUCTIONS` pour personnaliser l'agent ex√©cut√© par `/api/chatkit` (par d√©faut, le d√©p√¥t charge le workflow local d√©fini dans `backend/app/chatkit.py`).
  - Optionnel¬†: `ALLOWED_ORIGINS` pour lister les origines autoris√©es par CORS (s√©par√©es par des virgules, par d√©faut `*`)
  - Optionnel¬†: `ACCESS_TOKEN_EXPIRE_MINUTES` pour ajuster la dur√©e de validit√© du token (par d√©faut 120¬†min)
  - Optionnel¬†: `ADMIN_EMAIL` et `ADMIN_PASSWORD` pour provisionner automatiquement un compte administrateur au d√©marrage. Sans ces deux variables d√©finies dans votre fichier `.env`, aucun compte n'est cr√©√©.
  - Optionnel¬†: `DATABASE_CONNECT_RETRIES` / `DATABASE_CONNECT_DELAY` pour ajuster la strat√©gie d'attente au d√©marrage
- Start the dev server from the `backend/` directory: `uv run uvicorn server:app --reload` (ou `npm run backend:dev` √† la racine)

> üîÅ **Environnements virtuels** ‚Äî sans fichier `uv.lock`, c'est l'index PyPI qui fait foi. En CI/CD, √©pinglez vos versions en g√©n√©rant un lockfile temporaire (`uv pip compile backend/requirements.txt`) si vous avez besoin de reproductibilit√© stricte.

Le backend expose deux int√©grations compl√©mentaires :

- `/api/chatkit` est un serveur ChatKit auto‚Äëh√©berg√© bas√© sur `openai-chatkit`. Il persiste d√©sormais les fils, messages et pi√®ces jointes dans PostgreSQL via `PostgresChatKitStore`, tout en invoquant le workflow `run_workflow` d√©fini dans `backend/app/chatkit.py`. Vous pouvez toujours le personnaliser en fournissant `CHATKIT_AGENT_MODEL` / `CHATKIT_AGENT_INSTRUCTIONS`.
- `/api/chatkit/session` conserve le flux historique de l'application d'origine : un appel `httpx` vers `https://api.openai.com/v1/chatkit/sessions` pour r√©cup√©rer un `client_secret`. Cette route reste disponible pour tester rapidement un workflow existant (n√©cessite `CHATKIT_WORKFLOW_ID`).

> ‚ÑπÔ∏è **CORS et flux de conversation** ‚Äî l'API ChatKit h√©berg√©e ne renvoie pas syst√©matiquement d'en-t√™tes `Access-Control-Allow-Origin`, ce qui provoque un blocage lors de la diffusion SSE. Le backend expose donc un proxy `OPTIONS|POST /api/chatkit/proxy/{path:path}` qui relaie `https://api.openai.com/v1/chatkit/*`. Le serveur custom n'en a pas besoin mais le proxy reste utile pour le mode h√©berg√© ou pour r√©cup√©rer des logs bruts.

### Indexation JSON vectorielle (`pgvector`)

Le backend persiste d√©sormais les documents JSON enrichis dans trois tables d√©di√©es.
‚ö†Ô∏è Cette fonctionnalit√© repose exclusivement sur PostgreSQL (>= 14) avec l'extension `pgvector` activ√©e ; aucun mode de repli SQLite n'est pr√©vu.

- `json_vector_stores` pour r√©f√©rencer les collections (`slug`, titre optionnel, m√©tadonn√©es) ;
- `json_documents` pour stocker le JSON brut, sa version lin√©aris√©e et les m√©tadonn√©es associ√©es √† un document (`store_id`, `doc_id`) ;
- `json_chunks` pour conserver chaque extrait lin√©aris√©, son embedding `VECTOR`, le JSON source correspondant, les m√©tadonn√©es et les timestamps.

Au d√©marrage, `backend/app/startup.py` appelle automatiquement `CREATE EXTENSION IF NOT EXISTS vector` (PostgreSQL) puis cr√©e les index sp√©cialis√©s :

- `ivfflat` sur `json_chunks.embedding` (`vector_cosine_ops`) ;
- `GIN` plein texte sur `to_tsvector('simple', linearized_text)` ;
- `GIN` sur les colonnes `metadata` pour acc√©l√©rer les filtres JSONB.

Dans l'environnement Docker¬†Compose fourni, le service PostgreSQL repose sur l'image officielle `pgvector/pgvector:pg16`, qui
embarque l'extension `vector` pr√™te √† l'emploi. Sur une instance manag√©e, v√©rifiez aupr√®s de votre administrateur que le
paquet `pgvector` est install√© avant de lancer le backend.

Assurez-vous que l'utilisateur PostgreSQL dispose du droit `CREATE EXTENSION`. En cas de d√©ploiement manuel, vous pouvez forcer l'initialisation depuis la **racine du d√©p√¥t** avec :

```bash
# depuis la racine du d√©p√¥t
psql "postgresql://user:password@host:5432/chatkit" -c "CREATE EXTENSION IF NOT EXISTS vector"
```

L'ingestion est centralis√©e dans `backend/app/vector_store/service.py`. Le service lin√©arise automatiquement le JSON, d√©coupe le texte en segments avec chevauchement, g√©n√®re des embeddings via le mod√®le local `intfloat/multilingual-e5-small` (`sentence-transformers`) puis normalise les vecteurs avant de les enregistrer. Exemple minimal :

> üí° **D√©pendances syst√®me** ‚Äî Sur les distributions Debian/Ubuntu minimalistes (dont l'image officielle `python:3.11-slim` utilis√©e en Docker Compose), PyTorch n√©cessite la biblioth√®que `libgomp1` pour activer OpenMP. Le `Dockerfile` du backend installe ce paquet automatiquement ; sur une machine h√¥te, ajoutez-le via `sudo apt install libgomp1` si vous rencontrez une erreur ¬´¬†libgomp.so.1: cannot open shared object file¬†¬ª lors du chargement du mod√®le d'embedding.

```python
from backend.app.database import SessionLocal
from backend.app.vector_store import JsonVectorStoreService

payload = {"title": "Guide", "sections": ["Introduction", "FAQ"]}

with SessionLocal() as session:
    service = JsonVectorStoreService(session)
    service.ingest(
        "documentation",
        "guide-v1",
        payload,
        store_title="Documentation produit",
        document_metadata={"source": "wiki interne"},
    )
    session.commit()
```

Le chargement du mod√®le e5 est effectu√© paresseusement et mis en cache. Pensez √† relancer `npm run backend:sync` (depuis la racine) pour installer les nouvelles d√©pendances Python (`pgvector`, `sentence-transformers`).

### Biblioth√®que de widgets ChatKit

Un nouvel ensemble d'endpoints REST permet aux administrateurs de constituer une biblioth√®que de widgets r√©utilisables par les modules d'agent du workflow builder. Les d√©finitions sont stock√©es dans la table `widget_templates` et valid√©es via `chatkit.widgets.WidgetRoot` avant d'√™tre persist√©es.

Chaque cr√©ation ou mise √† jour indexe d√©sormais la d√©finition JSON dans un vector store d√©di√© (`chatkit-widgets`). Celui-ci est automatiquement cr√©√© au besoin et enrichi de m√©tadonn√©es (slug, titre, description). Les recherches hybrides peuvent ainsi exploiter la biblioth√®que de widgets pour sugg√©rer des composants pertinents dans vos prompts.

- `GET /api/widgets` ‚Äî lister l'ensemble des widgets disponibles (administrateur uniquement)¬†;
- `POST /api/widgets` ‚Äî cr√©er un widget (`slug`, titres/description optionnels et JSON d√©crivant le widget)¬†;
- `PATCH /api/widgets/{slug}` ‚Äî mettre √† jour le libell√©, la description ou la d√©finition JSON d'un widget¬†;
- `DELETE /api/widgets/{slug}` ‚Äî retirer un widget de la biblioth√®que¬†;
- `POST /api/widgets/preview` ‚Äî valider une d√©finition JSON et obtenir la version normalis√©e sans l'enregistrer.

Toutes ces routes sont prot√©g√©es par un contr√¥le d'acc√®s administrateur. Une fois `npm run backend:dev` lanc√© **depuis la racine du d√©p√¥t**, vous pouvez v√©rifier une d√©finition depuis le terminal avec¬†:

```bash
# depuis la racine du d√©p√¥t
curl -X POST http://localhost:8000/api/widgets/preview \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <TOKEN_ADMIN>" \
  -d '{
        "definition": {
          "type": "Card",
          "size": "lg",
          "children": [
            {"type": "Text", "id": "titre", "value": "R√©sum√©"},
            {"type": "Markdown", "id": "details", "value": "**Points cl√©s**"}
          ]
        }
      }'
```

Le JSON renvoy√© peut √™tre utilis√© tel quel comme sortie d'un module d'agent dans le workflow builder ChatKit.

### Bloc widget dans le workflow builder

Une fois la biblioth√®que aliment√©e, le workflow builder propose un **bloc widget** autonome dans la palette de gauche. Ajoutez-le apr√®s n'importe quel n≈ìud (agent, √©tat, condition‚Ä¶) pour diffuser le widget correspondant dans ChatKit d√®s que l'ex√©cution atteint ce bloc.

- Depuis la page **Workflows**, s√©lectionnez une version de workflow et cliquez sur **Modifier** pour afficher le builder.
- Dans la colonne de gauche, cliquez sur **Bloc widget** : un nouveau n≈ìud rose appara√Æt dans le canvas.
- S√©lectionnez le n≈ìud afin d'ouvrir l'inspecteur, choisissez le slug du widget √† afficher puis, si besoin, mappez les variables du widget avec des expressions de l'√©tat (ex. `state.resume`).
- Le bloc est compl√®tement ind√©pendant des √©tapes d'agent¬†: les widgets s'affichent imm√©diatement dans ChatKit sans attendre une r√©ponse textuelle.

Vous pouvez ainsi encha√Æner plusieurs widgets (cartes, formulaires, listes‚Ä¶) pour enrichir la conversation, tout en gardant la possibilit√© d'utiliser les widgets comme format de sortie d'un agent classique si n√©cessaire.

### Outil m√©t√©o expos√© au workflow ChatKit

Le backend expose √©galement un point d'entr√©e `GET /api/tools/weather` qui interroge l'API libre [Open-Meteo](https://open-meteo.com/) pour fournir les conditions actuelles d'une ville donn√©e. Cette route est pens√©e pour √™tre appel√©e depuis un outil de workflow ChatKit, mais elle reste publique afin de faciliter les tests manuels.

- Param√®tres¬†: `city` (obligatoire) et `country` (optionnel, code ou nom du pays pour affiner la recherche).
- R√©ponse¬†: temp√©rature, vitesse du vent, code m√©t√©o, description et fuseau horaire de la mesure.

Pour v√©rifier manuellement la r√©ponse, d√©marrez le serveur FastAPI puis, **depuis la racine du d√©p√¥t**, ex√©cutez par exemple¬†:

```bash
curl "http://localhost:8000/api/tools/weather?city=Lyon"
```

La charge utile retourn√©e est s√©rialisable en JSON et peut √™tre consomm√©e directement par un outil ChatKit (fonction Python, workflow Agent Builder, etc.).

### Exemple d'agent Python d√©di√©

Le module `backend/app/chatkit.py` regroupe d√©sormais l'exemple complet bas√© sur la librairie Python `agents`¬†: il expose le serveur `DemoChatKitServer`, les agents composant le workflow `run_workflow` et la logique de streaming utilis√©e par `/api/chatkit`.

### Int√©gration c√¥t√© widget ChatKit

Le composant React `MyChat` enregistre un gestionnaire `onClientTool` pour l'outil client `get_weather`. Lorsque le workflow d√©clenche cet outil, le navigateur appelle automatiquement `GET /api/tools/weather` avec les param√®tres fournis, puis renvoie la r√©ponse JSON au backend ChatKit. Aucune configuration suppl√©mentaire n'est n√©cessaire dans l'interface¬†: il suffit que le workflow √©mette un appel d'outil nomm√© `get_weather` avec au minimum `{ "city": "Paris" }`.

Le champ de composition autorise d√©sormais l'ajout de pi√®ces jointes (images, PDF, texte brut jusqu'√† 10¬†Mo, quatre fichiers maximum), ce qui refl√®te les capacit√©s de la session g√©n√©r√©e c√¥t√© backend.

Lorsque vous d√©finissez `VITE_CHATKIT_API_URL`, `src/MyChat.tsx` fournit une fonction `fetch` personnalis√©e qui ajoute automatiquement le jeton JWT √† chaque appel `fetch`, ce qui permet au serveur `/api/chatkit` d'identifier l'utilisateur c√¥t√© backend. Si vous restez sur l'API h√©berg√©e, le composant continue d'utiliser `/api/chatkit/session` et peut s'appuyer sur le proxy `/api/chatkit/proxy/*` pour contourner les restrictions CORS lors du streaming SSE.

> ‚ùó **Erreurs 502 sur un serveur externe** ‚Äî si le navigateur affiche `Failed to load resource: 502 (Bad Gateway)` lors d'un appel vers `VITE_CHATKIT_API_URL`, cela signifie que l'URL configur√©e ne r√©pond pas ou que le reverse proxy renvoie une erreur. Le widget remontera d√©sormais un message d'erreur explicite dans l'interface¬†; v√©rifiez que votre serveur ChatKit auto‚Äëh√©berg√© est joignable et que la variable `VITE_CHATKIT_API_URL` pointe bien vers l'endpoint `/api/chatkit` expos√©.

## Frontend (`frontend/`)

- Install JavaScript dependencies from within `frontend/`: `npm install` (ou `npm run frontend:install` √† la racine)
- Start the Vite dev server (also from `frontend/`): `npm run dev` (default URL `http://localhost:5173`; alias racine `npm run frontend:dev`)
- `src/App.tsx` d√©finit le routage entre l'accueil (`/`), la page de connexion (`/login`) et le panneau d'administration (`/admin`)
- Le widget ChatKit reste g√©r√© par `src/MyChat.tsx`, d√©sormais capable d'inclure automatiquement le token d'un utilisateur connect√©
- Aucun `package-lock.json` n'est versionn√© afin de toujours r√©cup√©rer la derni√®re version des d√©pendances lors du `npm install`. G√©rez un lock local ou CI si vous avez besoin de versions fig√©es.
- The project depends on React 19, matching the official starter app requirements for `@openai/chatkit-react`
- `vite.config.ts` proxies toutes les routes `/api/*` (dont `/api/chatkit`) vers le backend FastAPI expos√© sur le port¬†8000
- Le composant `MyChat` se branche par d√©faut sur `/api/chatkit`. Pour forcer le mode h√©berg√© (client secret), d√©finissez `VITE_CHATKIT_FORCE_HOSTED=true` dans votre `.env`. Pensez √† ajouter `VITE_CHATKIT_DOMAIN_KEY` si vous exposez votre propre domaine.
- `VITE_BACKEND_URL` d√©finit l'URL cible du backend pour l'ensemble des appels `/api/*`
- `VITE_HMR_HOST` doit se limiter √† un nom d'h√¥te (avec √©ventuellement un port). Une faute de frappe du type `https//mon-domaine`
  conduit le navigateur √† tenter de joindre `https://https//mon-domaine`, ce qui se traduit par une erreur DNS (`net::ERR_NAME_NOT_RESOLVED`).
  Le fichier `vite.config.ts` nettoie d√©sormais automatiquement ce genre d'entr√©e, mais il est pr√©f√©rable de corriger la valeur dans
  votre `.env` pour √©viter toute ambigu√Øt√©.
- Les requ√™tes de connexion basculent automatiquement sur `/api/auth/login` (m√™me origine) puis, en cas d'√©chec r√©seau, r√©essaient avec `VITE_BACKEND_URL`¬†; cela √©vite les erreurs ¬´¬†Failed to fetch¬†¬ª lorsque le navigateur n'a pas de r√©solution DNS pour `backend` en environnement Docker.
- `VITE_ALLOWED_HOSTS` permet d'ajouter une liste d'h√¥tes suppl√©mentaires autoris√©s par le serveur Vite (s√©par√©s par des virgules)
- `index.html` already loads the ChatKit CDN script: `<script src="https://cdn.platform.openai.com/deployments/chatkit/chatkit.js" async></script>`
- If you want to call OpenAI directly from the browser, `src/chatkit.ts` shows the fetch helper that uses `import.meta.env.VITE_OPENAI_API_SECRET_KEY`
- If `npm` complains about cache permissions, this repo ships with a local `.npmrc` pointing the cache to `.npm-cache/`; leave it in place or run `npm install --cache .npm-cache`

With both servers running (`uv run uvicorn server:app --reload` in `backend/` and `npm run dev` inside `frontend/`), navigating to the Vite dev URL displays the embedded ChatKit widget, aliment√© soit par votre agent local (`/api/chatkit`), soit par le workflow h√©berg√© si vous avez conserv√© le mode `client_secret`.

### Utiliser votre propre backend ChatKit

Ce d√©p√¥t embarque d√©j√† une impl√©mentation de r√©f√©rence (`DemoChatKitServer`) accessible sur `/api/chatkit`. Elle s'appuie sur `openai-chatkit`, un store PostgreSQL (`PostgresChatKitStore`) et l'Agents SDK pour ex√©cuter `run_workflow` (d√©fini dans `backend/app/chatkit.py`). Vous pouvez la conserver telle quelle, la personnaliser (instructions, mod√®le, persistance) ou repartir d'un projet vierge suivant les √©tapes ci-dessous.

Pour les int√©grations avanc√©es, vous pouvez auto‚Äëh√©berger ChatKit et piloter le widget via votre propre serveur. Cette approche vous permet de g√©rer l'authentification, l'orchestration d'outils et la r√©sidence des donn√©es selon vos exigences.

1. **Installer le serveur ChatKit** ‚Äî Depuis le r√©pertoire de votre projet serveur (par exemple `backend/` ou un d√©p√¥t d√©di√©) et dans un environnement Python virtuel (cr√©√© via `uv` ou `python -m venv`), installez la d√©pendance :
   ```bash
   pip install openai-chatkit
   ```
2. **Impl√©menter une classe de serveur** ‚Äî Cr√©ez un module (par exemple `my_chatkit_server.py`) qui h√©rite de `ChatKitServer` et surcharge la m√©thode `respond`. Vous pouvez r√©utiliser l'exemple suivant en l'adaptant √† vos agents et √† vos outils :
   ```python
   class MyChatKitServer(ChatKitServer):
       assistant_agent = Agent[AgentContext](
           model="gpt-4.1",
           name="Assistant",
           instructions="Vous √™tes un assistant utile",
       )

       async def respond(self, thread, input, context):
           agent_context = AgentContext(thread=thread, store=self.store, request_context=context)
           result = Runner.run_streamed(
               self.assistant_agent,
               await to_input_item(input, self.to_message_content),
               context=agent_context,
           )
           async for event in stream_agent_response(agent_context, result):
               yield event
   ```
   Adaptez `to_message_content` si vous acceptez des fichiers ou des images.
3. **Exposer l'endpoint HTTP** ‚Äî Avec FastAPI, servez votre instance via un point d'entr√©e `POST /chatkit` et relayez les r√©ponses `StreamingResult` en SSE :
   ```python
   app = FastAPI()
   data_store = SQLiteStore()
   file_store = DiskFileStore(data_store)
   server = MyChatKitServer(data_store, file_store)

   @app.post("/chatkit")
   async def chatkit_endpoint(request: Request):
       result = await server.process(await request.body(), {})
       if isinstance(result, StreamingResult):
           return StreamingResponse(result, media_type="text/event-stream")
       return Response(content=result.json, media_type="application/json")
   ```
4. **Persister les donn√©es** ‚Äî Impl√©mentez l'interface `chatkit.store.Store` pour conserver les fils, messages et fichiers selon votre base de donn√©es (PostgreSQL, DynamoDB, etc.).
5. **G√©rer les fichiers** ‚Äî Fournissez un `FileStore` si vous autorisez les uploads (directs ou en deux temps via URL sign√©e) et exposez les pr√©visualisations n√©cessaires au widget.
6. **D√©clencher des outils c√¥t√© client** ‚Äî Enregistrez vos outils √† la fois sur l'agent et c√¥t√© client, puis d√©clenchez‚Äëles via `ctx.context.client_tool_call` lorsque l'agent doit renvoyer un travail au navigateur.
7. **Exploiter le contexte serveur** ‚Äî Passez un objet `context` personnalis√© √† `server.process(body, context)` pour propager l'identit√© de l'utilisateur, ses r√¥les ou toute autre m√©tadonn√©e requise par vos r√®gles m√©tier.

Une fois votre serveur en place, pointez le widget ChatKit (via `apiURL`) vers votre nouvelle route `/chatkit`. Vous b√©n√©ficiez alors d'un contr√¥le complet sur la session, la strat√©gie d'authentification et l'ex√©cution des outils tout en conservant l'ergonomie du composant ChatKit.

### Configurer le frontend Vite pour un serveur ChatKit personnalis√©

1. **Cr√©ez un fichier `.env` √† la racine** en dupliquant `.env.example`.
2. **Renseignez `VITE_CHATKIT_API_URL`** avec l'URL publique de votre serveur ChatKit (par exemple `https://chatkit.example.com/chatkit`). Sans cette variable, l'application pointe par d√©faut sur `/api/chatkit` (le backend FastAPI inclus).
3. **Optionnel¬†: fournissez `VITE_CHATKIT_DOMAIN_KEY`** si vous disposez d'une cl√© enregistr√©e aupr√®s d'OpenAI. Sans valeur, le widget fonctionnera n√©anmoins en mode auto-h√©berg√© et la v√©rification de domaine sera ignor√©e.
4. **Optionnel¬†: contournez la v√©rification distante** ‚Äî d√©finissez `VITE_CHATKIT_SKIP_DOMAIN_VERIFICATION=true` si votre environnement ne peut pas joindre l'API OpenAI `domain_keys/verify_hosted`. Dans ce cas, toute requ√™te de v√©rification est court‚Äëcircuit√©e c√¥t√© navigateur et le widget continue de fonctionner.
5. **Choisissez la strat√©gie d'upload** via `VITE_CHATKIT_UPLOAD_STRATEGY` :
   - `two_phase` si votre serveur fournit des URL sign√©es via un √©change en deux temps.
   - `direct` si le serveur accepte un upload direct. Dans ce cas, pr√©cisez aussi `VITE_CHATKIT_DIRECT_UPLOAD_URL`.
6. **Optionnel¬†: forcer le mode h√©berg√©** ‚Äì d√©finissez `VITE_CHATKIT_FORCE_HOSTED=true` si vous souhaitez ignorer le serveur custom et g√©n√©rer un `client_secret` (utile lorsque vous testez un workflow existant).
7. **Red√©marrez le serveur Vite** (`npm run frontend:dev` depuis la racine) pour recharger les nouvelles variables.

 Lorsque ces variables sont d√©finies, le composant `MyChat` n'appelle plus `/api/chatkit/session` et dialogue directement avec votre serveur via l'API ChatKit fournie par le backend FastAPI. Sans cl√© de domaine, le frontend ignore la v√©rification distante et reste pleinement fonctionnel en mode auto-h√©berg√©. Si `VITE_CHATKIT_SKIP_DOMAIN_VERIFICATION=true`, la requ√™te correspondante est neutralis√©e et le widget s'ex√©cute sans d√©pendre de l'endpoint OpenAI `domain_keys/verify_hosted`. Vous pouvez √† tout moment forcer le flux h√©berg√© en d√©finissant `VITE_CHATKIT_FORCE_HOSTED=true`. Dans le mode auto-h√©berg√©, si aucune strat√©gie d'upload n'est fournie, les pi√®ces jointes sont automatiquement d√©sactiv√©es afin d'√©viter les erreurs de configuration.

### V√©rifier rapidement votre fichier `.env`

Un doute sur la configuration appliqu√©e¬†? Depuis la **racine du d√©p√¥t**, lancez¬†:

```bash
npm run diagnostic:env
```

Le script `scripts/check-env.js` parcourt votre fichier `.env` et signale les oublis les plus fr√©quents¬†:

- pr√©sence et format de `OPENAI_API_KEY`¬†;
- correspondance des URL (`VITE_BACKEND_URL`, `VITE_CHATKIT_API_URL`)¬†;
- strat√©gie d'upload et variables associ√©es¬†;
- cl√© de domaine et options de for√ßage du mode h√©berg√©.

En sortie, chaque ligne est pr√©fix√©e par ‚úÖ ou ‚ö†Ô∏è selon que le param√®tre semble correct ou n√©cessite votre attention. En cas d'erreur 502 persistante, le script rappelle √©galement la commande `curl -i <URL>` √† ex√©cuter pour v√©rifier que votre reverse proxy relaie bien l'endpoint `/api/chatkit`.

## Lancement via Docker Compose

Depuis la racine du d√©p√¥t, vous pouvez orchestrer le backend FastAPI et le frontend Vite via Docker¬†Compose¬†:

1. Cr√©ez un fichier `.env` √† la racine (au m√™me niveau que `docker-compose.yml`) en vous basant sur `.env.example` et renseignez au minimum¬†:
   ```env
   OPENAI_API_KEY="sk-..."
   AUTH_SECRET_KEY="change-me"
   # Optionnel¬†: ajustez la connexion PostgreSQL (d√©faut : postgresql+psycopg://chatkit:chatkit@db:5432/chatkit).
   # En Docker¬†Compose, laissez `db` comme hostname ou omettez compl√®tement cette variable pour conserver la valeur par d√©faut.
   # DATABASE_URL="postgresql+psycopg://user:password@host:5432/chatkit"
   # Optionnel : activez le mode workflow h√©berg√©
   # CHATKIT_WORKFLOW_ID="wf_..."
   # Optionnel : personnalisez l'agent ex√©cut√© par /api/chatkit
   # CHATKIT_AGENT_MODEL="gpt-4.1-mini"
   # CHATKIT_AGENT_INSTRUCTIONS="Tu es un assistant conversationnel‚Ä¶"
   # Optionnel : alignez le frontend sur votre endpoint ChatKit
   # VITE_CHATKIT_API_URL="https://chatkit.example.com/api/chatkit"
   # VITE_CHATKIT_DOMAIN_KEY="domain_pk_..."
   # VITE_CHATKIT_FORCE_HOSTED="false"
   # VITE_CHATKIT_SKIP_DOMAIN_VERIFICATION="true"
   # VITE_CHATKIT_UPLOAD_STRATEGY="two_phase"
   # VITE_CHATKIT_DIRECT_UPLOAD_URL="https://chatkit.example.com/upload"
   # Optionnel : ajustez le port d'exposition du frontend
   VITE_PORT=5183
   # Optionnel : ajustez le hostname utilis√© par le HMR (utile derri√®re un tunnel/proxy)
   VITE_HMR_HOST=localhost
   # Optionnel : alignez la liste d'h√¥tes autoris√©s par Vite (s√©par√©s par des virgules)
   # VITE_ALLOWED_HOSTS="chatkit.example.com"
   ```
   Pour cr√©er automatiquement un compte administrateur lors du d√©marrage du backend, ajoutez dans ce m√™me fichier¬†:

   ```env
   ADMIN_EMAIL="admin@example.com"
   ADMIN_PASSWORD="adminpass"
   ```

   Tant que ces variables ne figurent pas dans votre `.env`, aucun compte administrateur n'est provisionn√© par d√©faut.
   Les autres variables d'environnement expos√©es dans `docker-compose.yml` disposent de valeurs par d√©faut (`VITE_ALLOWED_HOSTS`, `VITE_HMR_PROTOCOL`, `VITE_HMR_CLIENT_PORT`, `VITE_BACKEND_URL`, etc.) que vous pouvez √©galement surcharger dans `.env` si n√©cessaire.
2. Depuis la racine du projet, lancez `docker compose up --build` pour d√©marrer les trois services (backend, frontend, base PostgreSQL). Cette premi√®re ex√©cution construit l'image `backend` √† partir de `backend/Dockerfile` (installation de `libgomp1` + d√©pendances Python) et r√©cup√®re l'image `pgvector/pgvector:pg16` pour la base de donn√©es, avec l'extension `vector` d√©j√† disponible. Le backend r√©pond sur `http://localhost:8000`, la base de donn√©es sur `localhost:5432` et le frontend sur `http://localhost:${VITE_PORT}`. Le build Docker copie le dossier `chatkit-python/` afin que `pip` installe la version embarqu√©e d'`openai-chatkit`.
3. Utilisez `docker compose down` pour arr√™ter l'environnement de d√©veloppement. Rejouez `docker compose up --build` √† chaque fois que vous modifiez `backend/requirements.txt` ou le Dockerfile¬†; dans les autres cas, un simple `docker compose up` suffit.

Les volumes mont√©s vous permettent de modifier le code localement tout en profitant du rafra√Æchissement √† chaud c√¥t√© frontend (`npm run dev -- --host 0.0.0.0`) et du rechargement automatique d'Uvicorn. Le volume nomm√© `postgres-data` conserve l'√©tat de la base entre deux relances.

### Exemple derri√®re un reverse proxy Nginx

Si vous exposez l'environnement de d√©veloppement via Nginx (par exemple sur `https://chatkit.example.com`), configurez d'abord `.env` √† la racine¬†:

- `VITE_BACKEND_URL="https://chatkit.example.com/api"` pour forcer le frontend √† appeler le backend via le reverse proxy.
- `VITE_HMR_HOST="chatkit.example.com"`, `VITE_ALLOWED_HOSTS="chatkit.example.com"`, `VITE_HMR_PROTOCOL="wss"` et `VITE_HMR_CLIENT_PORT=443` afin que le hot reload Vite continue de fonctionner √† travers le proxy.

Ensuite, adaptez votre bloc `server` Nginx (fichier `sites-available/chatkit.conf`, √† activer via `ln -s` depuis `/etc/nginx/sites-enabled/`). Les fichiers de certificats TLS ne doivent **pas** √™tre cr√©√©s √† la main¬†: laissez `certbot` g√©n√©rer et renouveler `/etc/letsencrypt/live/...` pour vous (`sudo certbot --nginx -d chatkit.example.com` ou `sudo certbot certonly --nginx ‚Ä¶`). Une fois le certificat obtenu, r√©f√©rencez simplement les chemins fournis par `certbot` dans votre configuration¬†:

```nginx
map $http_upgrade $connection_upgrade {
  default upgrade;
  '' close;
}

server {
  listen 80;
  listen 443 ssl;
  server_name chatkit.example.com;

  # Certificats TLS g√©r√©s automatiquement par certbot/letsencrypt
  ssl_certificate     /etc/letsencrypt/live/chatkit.example.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/chatkit.example.com/privkey.pem;

  location /api/ {
    proxy_pass http://127.0.0.1:8000/api/;
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;
  }

  location / {
    proxy_pass http://127.0.0.1:5173/; # Ajustez le port si vous avez chang√© VITE_PORT
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;
  }
}
```

Red√©marrez ensuite Nginx (`sudo systemctl reload nginx`) et relancez `docker compose up` depuis la racine si n√©cessaire. Le proxy transf√©rera les requ√™tes HTTP classiques sur `/` vers Vite et les appels API `/api/‚Ä¶` vers FastAPI, tout en pr√©servant les websockets n√©cessaires au HMR.

`certbot` cr√©era et renouvellera automatiquement les fichiers dans `/etc/letsencrypt/live/chatkit.example.com/`; vous n'avez donc rien √† ajouter manuellement dans votre d√©p√¥t ou sur le serveur. Pensez simplement √† v√©rifier que le timer `certbot.timer` est actif (`systemctl status certbot.timer`) pour garantir le renouvellement p√©riodique des certificats.
