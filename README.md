<div align="center">
  <img src="frontend/src/assets/favicon.svg" alt="edxo logo" width="120" height="120"/>
  <h1>edxo</h1>
  <p><strong>Open-source workflow builder for conversational AI assistants</strong></p>
</div>

---

edxo is a personal project I built to explore complex conversational AI workflows. I initially tried using OpenAI's AgentKit, but found it incomplete for my needs—particularly around visual workflow building, LMS integrations, and extensibility. So I built edxo: a no-code platform to create intelligent assistants with a drag-and-drop interface.

If you need to build educational chatbots, customer support agents, or any custom conversational assistant, this project might help.

---

## Why I built this

I wanted to create complex conversational flows without rewriting code every time. OpenAI's AgentKit was a good starting point, but lacked:
- Visual workflow editor for non-technical users
- LMS integration (LTI 1.3) for education use cases
- Advanced vector store management
- Voice/telephony capabilities
- Extensible plugin system (MCP)

edxo builds on AgentKit's concepts but adds a complete platform layer on top.

## What it does

- **Visual Workflow Builder**: Create conversational flows with drag-and-drop
- **Multi-model AI**: OpenAI, Claude, Gemini, Mistral via LiteLLM
- **Vector Stores**: Index your documents for context-aware responses
- **Voice Mode**: Real-time voice conversations + SIP telephony
- **LMS Integration**: LTI 1.3 for Moodle/Canvas (if you're in education)
- **MCP Support**: Connect assistants to external data sources
- **Real-time Monitoring**: Track workflow executions and analyze conversations

## Use cases

Originally built for education (hence the LMS integration), but works for:
- Educational assistants in learning management systems
- Customer support / help desk automation
- Employee onboarding
- Domain-specific conversational agents
- Rapid prototyping of AI agents
- Anything requiring a conversational workflow

---

## Quick start

### Prerequisites

- **Docker** and **Docker Compose** (recommended)
- Or local install: Python 3.11+, Node.js 20+, PostgreSQL 16+, Redis 7+

### Installation with Docker (5 minutes)

1. **Clone the repo**
   ```bash
   git clone <repo-url>
   cd edxo
   ```

2. **Configure environment**
   ```bash
   cp .env.example .env
   ```

   Edit `.env` with your settings:
   ```bash
   # Required: Your AI provider API key
   OPENAI_API_KEY=sk-your-openai-key

   # Security (CHANGE THESE!)
   AUTH_SECRET_KEY=a-very-long-random-secret-key

   # Admin account
   ADMIN_EMAIL=admin@example.com
   ADMIN_PASSWORD=SecurePassword123!

   # Basic configuration
   ALLOWED_ORIGINS=http://localhost:5183,http://127.0.0.1:5183
   DATABASE_URL=postgresql+psycopg://chatkit:chatkit@localhost:5432/chatkit
   ```

3. **Launch the platform**
   ```bash
   docker-compose up -d
   ```

4. **Access the interface**
   - Frontend: http://localhost:5183
   - API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

5. **First login**
   - Email: the one you set in `ADMIN_EMAIL`
   - Password: the one you set in `ADMIN_PASSWORD`

---

## User guide

### 1. Create your first workflow

1. Login as admin
2. Go to **Workflow Builder** in the menu
3. Create a new workflow or duplicate an example
4. Use the visual editor to:
   - Add conversation nodes
   - Define conditional branching
   - Configure AI responses
   - Add interactive widgets
5. Preview your workflow
6. Publish to production when satisfied

### 2. Integrate with your LMS (optional)

#### LTI configuration in edxo

1. Go to **Admin** → **LTI**
2. Get your tool information:
   - **Redirect URL**: For OIDC
   - **Deep Link URL**: For course integration
   - **Public Key URL**: For JWT validation
3. Click **Create a registration**
4. Enter your LMS platform information:
   - **Issuer**: Your LMS unique identifier
   - **Client ID**: Provided by your LMS
   - **Authorization Endpoint**, **Token Endpoint**, **KeySet URL**: Your LMS URLs

#### Configuration in Moodle

1. **Site administration** → **Plugins** → **External tool** → **Manage tools**
2. Click **Configure a tool manually**
3. Fill in:
   - **Tool name**: edxo
   - **Tool URL**: `http://your-server:8000/lti/launch`
   - **LTI version**: LTI 1.3
   - **Public key type**: Keyset URL
   - **Public keyset**: `http://your-server:8000/lti/jwks`
   - **Initiate login URL**: `http://your-server:8000/lti/login`
   - **Redirection URI(s)**: `http://your-server:8000/lti/launch`
4. Enable **Deep Linking**
5. Save and retrieve the **Client ID** to add in edxo

#### Configuration in Canvas

1. **Settings** → **Apps** → **View App Configurations**
2. Click **+ App**
3. Select **By URL** or **Paste JSON**
4. Use the JSON configuration generated by edxo
5. Add the registration in edxo with Canvas information

### 3. Add knowledge bases

1. **Admin** → **Vector Stores**
2. Create a new store
3. Upload your documents (PDF, TXT, Markdown, etc.)
4. Link the store to your workflows
5. The assistant can now query these documents to respond to users

### 4. Configure a custom AI model

1. **Admin** → **Model Providers**
2. Add a new provider (e.g., Azure OpenAI, LiteLLM)
3. **Admin** → **Models**
4. Configure available models and their capabilities
5. Select the default model for your workflows

### 5. Customize appearance

1. **Admin** → **Appearance**
2. Upload your logo
3. Customize colors
4. Define welcome messages
5. Configure translations if needed

---

## Technical architecture

```
edxo/
├── backend/                      # FastAPI application (Python)
│   ├── app/
│   │   ├── routes/               # REST endpoints
│   │   │   ├── workflows.py      # Workflow Builder API
│   │   │   ├── lti.py            # LTI 1.3 endpoints
│   │   │   ├── workflow_monitor_ws.py  # WebSocket monitoring
│   │   │   └── ...
│   │   ├── workflows/            # Workflow management service
│   │   ├── lti/                  # Complete LTI 1.3 service
│   │   │   ├── service.py        # LTI logic
│   │   │   └── ags.py            # Assignment & Grade Services
│   │   ├── vector_store/         # Semantic search
│   │   ├── telephony/            # SIP/VoIP
│   │   ├── chatkit/              # ChatKit integration
│   │   ├── mcp/                  # Model Context Protocol
│   │   ├── models.py             # SQLAlchemy models
│   │   └── schemas.py            # Pydantic validation
│   ├── migrations/               # Alembic migrations
│   └── tests/                    # Unit tests
├── frontend/                     # React + TypeScript interface
│   └── src/
│       ├── features/
│       │   └── workflow-builder/ # Visual workflow editor
│       ├── pages/
│       │   ├── WorkflowBuilderPage.tsx
│       │   ├── AdminLtiPage.tsx
│       │   ├── AdminWorkflowMonitorPage.tsx
│       │   ├── VectorStoresPage.tsx
│       │   └── ...
│       └── components/           # Reusable components
├── chatkit-python/               # ChatKit Python library
├── docker-compose.yml            # Complete orchestration
└── README.md                     # This file
```

### Tech stack

**Backend**
- FastAPI (async REST API)
- SQLAlchemy + PostgreSQL (with pgVector)
- Celery + Redis (async tasks)
- LiteLLM (multi-model integration)
- PyJWT (LTI authentication)
- PJSIP (SIP telephony)

**Frontend**
- React 18 with TypeScript
- Vite (ultra-fast builds)
- React Flow (visual workflow builder)
- React Hook Form + Zod (validation)
- TanStack Query (server state management)

**Infrastructure**
- Docker & Docker Compose
- Nginx (production reverse proxy)
- PostgreSQL 16 (pgvector for semantic search)
- Redis 7 (cache & Celery broker)

---

## Advanced configuration

### AI Providers

#### OpenAI (default)
```bash
MODEL_PROVIDER=openai
OPENAI_API_KEY=sk-your-key
CHATKIT_API_BASE=https://api.openai.com
```

#### LiteLLM (multi-provider)
```bash
MODEL_PROVIDER=litellm
LITELLM_API_BASE=http://localhost:4000
LITELLM_API_KEY=sk-litellm

# Add necessary keys
ANTHROPIC_API_KEY=sk-ant-...
GEMINI_API_KEY=...
MISTRAL_API_KEY=...
```

#### Azure OpenAI
```bash
MODEL_PROVIDER=openai
MODEL_API_BASE=https://your-instance.openai.azure.com
AZURE_OPENAI_API_KEY=your-azure-key
```

### Voice mode

Server-side configuration:
```bash
CHATKIT_REALTIME_MODEL=gpt-4o-realtime-preview-2024-12-17
CHATKIT_REALTIME_INSTRUCTIONS="Helpful educational assistant"
CHATKIT_REALTIME_VOICE=verse
```

Client-side configuration (frontend):
```bash
VITE_VOICE_SESSION_URL=/api/chatkit/voice/session
VITE_VOICE_DEFAULT_MODEL=gpt-4o-realtime-preview-2024-12-17
VITE_VOICE_DEFAULT_VOICE=alloy
```

### SIP Telephony

To allow users to call your assistants by phone:

```bash
SIP_BIND_HOST=0.0.0.0
SIP_BIND_PORT=40118
SIP_CONTACT_HOST=your-public-ip
SIP_TRANSPORT=udp
```

Then configure a SIP account in **Admin** → **SIP Accounts**.

### Rate Limiting

Protect your API with rate limiting:
```bash
RATE_LIMIT_ENABLED=true
CELERY_BROKER_URL=redis://localhost:6379/0
```

Disable in development:
```bash
RATE_LIMIT_ENABLED=false
```

### Internationalization

Add languages in **Admin** → **Languages**:
- Automatic multilingual interface
- Customizable translations
- RTL support for Arabic/Hebrew

---

## Monitoring and maintenance

### Logs

**Development** (colored console logs):
```bash
ENVIRONMENT=development
LOG_LEVEL=DEBUG
```

**Production** (structured JSON logs):
```bash
ENVIRONMENT=production
LOG_LEVEL=INFO
LOG_FORMAT=json
```

### Workflow Monitor

Real-time monitoring interface:
- **Admin** → **Workflow Monitor**
- Visualize executions in real-time
- Identify errors and bottlenecks
- Analyze user journeys

### Metrics

Check usage metrics:
- Number of sessions per workflow
- Average response time
- Satisfaction rate (if configured)
- Usage by AI model

### Backup

**PostgreSQL database**:
```bash
docker-compose exec db pg_dump -U chatkit chatkit > backup_$(date +%Y%m%d).sql
```

**Restore**:
```bash
docker-compose exec -T db psql -U chatkit chatkit < backup_20240615.sql
```

**Workflows and configurations**:
- Export your workflows from the interface (JSON)
- Backup the `.env` file
- Keep LTI registrations

---

## Production deployment

### Security checklist

- [ ] Change `AUTH_SECRET_KEY` (minimum 32 random characters)
- [ ] Use strong passwords for PostgreSQL and Redis
- [ ] Configure `ALLOWED_ORIGINS` with your domains only
- [ ] Enable HTTPS with valid SSL/TLS certificates
- [ ] Enable rate limiting
- [ ] Configure JSON logs (`LOG_FORMAT=json`)
- [ ] Set `ENVIRONMENT=production`
- [ ] Disable debug logs
- [ ] Configure automatic backups
- [ ] Restrict network access to necessary ports

### Production environment variables

```bash
# Environment
ENVIRONMENT=production
LOG_LEVEL=INFO
LOG_FORMAT=json

# Security
AUTH_SECRET_KEY=<generated-with-openssl-rand-base64-32>
ALLOWED_ORIGINS=https://edxo.your-domain.com
RATE_LIMIT_ENABLED=true

# Database (use strong passwords)
DATABASE_URL=postgresql+psycopg://edxo:SECURE_PASSWORD@postgres:5432/edxo
CELERY_BROKER_URL=redis://:REDIS_PASSWORD@redis:6379/0

# Admin
ADMIN_EMAIL=admin@your-domain.com
ADMIN_PASSWORD=<very-secure-password>

# AI
OPENAI_API_KEY=<your-production-key>
```

### Nginx reverse proxy

```nginx
upstream backend {
    server 127.0.0.1:8000;
}

upstream frontend {
    server 127.0.0.1:5183;
}

server {
    listen 443 ssl http2;
    server_name edxo.your-domain.com;

    ssl_certificate /etc/letsencrypt/live/edxo.your-domain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/edxo.your-domain.com/privkey.pem;

    # SSL security
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;

    # API Backend
    location /api/ {
        proxy_pass http://backend/api/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # LTI Endpoints
    location /lti/ {
        proxy_pass http://backend/lti/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Frontend
    location / {
        proxy_pass http://frontend/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
    }
}

# HTTP to HTTPS redirect
server {
    listen 80;
    server_name edxo.your-domain.com;
    return 301 https://$server_name$request_uri;
}
```

---

## Tests

### Backend tests

```bash
cd backend

# Unit tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=app --cov-report=html

# Specific tests
pytest tests/test_workflows.py -v
pytest tests/test_lti.py -v
```

### LTI integration tests

```bash
# Check LTI configuration
./check_lti.sh

# Test complete workflow
./test_example.sh
```

### Telephony tests

```bash
# Minimal incoming call test
./test_incoming_calls_minimal.py

# Complete test with audio bridge
./test_incoming_calls_with_bridge.py

# Audio port creation test
./test_audio_port_creation.py
```

---

## Contributing

This is a personal project, but contributions are welcome! If you find it useful and want to improve it:

1. Fork the project
2. Create a branch: `git checkout -b feature/my-awesome-feature`
3. Commit: `git commit -m 'Add my awesome feature'`
4. Push: `git push origin feature/my-awesome-feature`
5. Open a Pull Request

### Code standards

**Python**
- Follow PEP 8
- Use Black for formatting
- Use isort for imports
- Type hints required
- Docstrings for public functions

**TypeScript**
- Follow configured ESLint rules
- Strict types (no `any` unless justified)
- Functional components with hooks
- Tests for critical components

**Commits**
- Messages in English
- Format: `Type: Short description`
- Types: Feature, Fix, Refactor, Docs, Test, Chore

### Areas that could use help

- [ ] More LMS support (Brightspace, Schoology, etc.)
- [ ] Workflow marketplace/sharing
- [ ] Advanced analytics for educators
- [ ] OpenAI Assistants API support
- [ ] H5P integration for interactive content
- [ ] Mobile app (React Native)
- [ ] SSO with SAML/OAuth2
- [ ] Gamification (badges, points, leaderboards)

---

## FAQ

### How is this different from ChatGPT?

edxo is designed for **custom conversational workflows**:
- Visual workflow builder (no-code)
- Native LMS integration (stay in Moodle/Canvas)
- Customizable flows per course/module
- Full control over user data
- Self-hosting possible (data sovereignty)

### Can I use models other than GPT?

Yes! edxo supports:
- Claude (Anthropic) via LiteLLM
- Gemini (Google) via LiteLLM
- Mistral AI
- Llama (via Ollama or LiteLLM)
- Azure OpenAI
- Any OpenAI-compatible API

### Is it free?

The software is open source, but you need to:
- Provide your own infrastructure (server)
- Pay for AI provider APIs (OpenAI, Anthropic, etc.)

### How much does it cost in AI API calls?

Depends on your usage. Example with GPT-4:
- 1000 user messages ≈ $5-10
- To reduce costs: use GPT-3.5, Claude Haiku, or self-host Llama

### Is user data secure?

Yes:
- You host the platform (self-hosting possible)
- HTTPS encryption required
- GDPR compliant if configured correctly
- Conversations with AI go through provider APIs (check their ToS)

### Can I use it without an LMS?

Yes! edxo works standalone:
- Web interface accessible directly
- Manual user account management
- No need for LTI if you don't use an LMS

---

## Resources

### Documentation
- **LTI 1.3**: https://www.imsglobal.org/spec/lti/v1p3/
- **OpenAI Realtime API**: https://platform.openai.com/docs/guides/realtime
- **LiteLLM**: https://docs.litellm.ai/
- **FastAPI**: https://fastapi.tiangolo.com/
- **React Flow**: https://reactflow.dev/

### Community
- GitHub Issues: Report bugs
- GitHub Discussions: Ask questions

---

## License

MIT

---

## Acknowledgments

- **OpenAI** for AgentKit (the inspiration) and the Realtime API
- **Anthropic** for Claude
- **LiteLLM** community for the multi-provider proxy
- All open-source contributors

---

**Built for fun. Shared in case it helps others.**
